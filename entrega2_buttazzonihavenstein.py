# -*- coding: utf-8 -*-
"""Entrega2_ButtazzoniHavenstein

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19SnTqToOwqeIykHhSY9W-xODkMNEzWJ2
"""

#link KAGGLE - https://www.kaggle.com/rikdifos/credit-card-approval-prediction?select=credit_record.csv

"""**PROYECTO FINAL CURSO DATA SCIENCE CODERHOUSE 2022**

Trabajaremos sobre un dataset de TARJETAS DE CRÉDITO con el objetivo de definir clusters de clientes centrándonos en la posibilidad de cobro ante los mismos. Entonces, de esta forma, tendremos una cluesterización de clientes que permita a la empresa verificar si éste sera un cliente cumplidor o no.
"""

#Importamos librerías
import pandas as pd
import numpy as np
import seaborn as sns
from seaborn import distplot
import matplotlib.pyplot as plt

#Leemos los dataset
aplication = pd.read_csv("/content/application.csv")
aplication

#Leemos los dataset
credit = pd.read_csv("/content/credit.csv")
credit

#Unimos los dataset
df = pd.merge(aplication,credit,on="ID")
df

df.drop(df.loc[df['MONTHS_BALANCE']!= 0].index, inplace=True)

df

"""En los siguientes pasos se realizará un análisis EDA para identificar variables y su comportamiento"""

#Vemos resumen del dataset
df.describe().round().T

#Reemplazo los valores str por int en "ACCOUNT STATUS"
df= df.replace({"C":"6","X":"7"})
df

#Vemos el tamaño
df.shape

#Vemos nombre de columnas
df.columns

#Cambiamos nombres de columnas
df = df.rename(columns={"CODE_GENDER":"GENDER", "FLAG_OWN_CAR":"CAR","FLAG_OWN_REALTY":"PROPERTIES","CNT_CHILDREN":"CHILDREN", "AMT_INCOME_TOTAL":"ANNUAL_INCOME", "NAME_INCOME_TYPE":"INCOME_CATEGORY", "NAME_EDUCATION_TYPE":"EDUCATION_LEVEL", "NAME_FAMILY_STATUS":"MARITAL_STATUS", "NAME_HOUSING_TYPE":"WAY_OF_LIVING", "DAYS_BIRTH":"BIRTHDAY", "DAYS_EMPLOYED":"START_DAY", "FLAG_MOBIL":"MOBILE_PHONE", "FLAG_WORK_PHONE":"WORK_PHONE", "FLAG_PHONE": "PHONE", "FLAG_EMAIL": "EMAIL", "OCCUPATION_TYPE":"OCCUPATION", "CNT_FAM_MEMBERS":"FAMILY_SIZE", "MONTHS_BALANCE":"MONTHS_OF_BALANCE", "STATUS":"ACCOUNT_STATUS"})
df

df.columns

"""Se cambió el nombre de las columnas para una mejor identificación de las variables. 
A continuación, se hará una breve descripción de ellas:

**ID:** Numero de cliente

**GENDER:**	Género del cliente.

**CAR**	posee o no auto

**PROPERTIES**	posee propiedades

**CHILDREN**	Numero de niños	

**ANNUAL INCOME** Ingresos anuales

**INCOME CATEGORY**	Categoría de ingresos	

**EDUCATION TYPE** Nivel de Educación	

**MARITAL STATUS**	Estado civil	

**WAY OF LIVING**	Modo de vivir	

**BIRTHDAY**	Cumpleaños - Cuenta hacia atrás desde el día actual (0), -1 significa ayer,etc.

**START DAY**	Fecha de inicio del empleo	Contar hacia atrás desde el día actual (0). Si es positivo, significa la persona actualmente desempleada.

**MOBILE PHONE** Posee telefono movil

**WORK PHON**E	Posee teléfono de trabajo

**PHONE**	Posee teléfono

**E-MAIL** hay un correo electronico	

**OCCUPATION**	Ocupación	

**FAMILY SIZE**	Tamaño de la familia	

**MONTHS OF BALANCE**	El mes de los datos extraídos es el punto de partida, al revés, 0 es el mes actual, -1 es el mes anterior, etc.

**ACCOUNT STATUS**
0: 1-29 días de atraso 
1: 30-59 días de atraso 
2: 60-89 días de atraso 
3: 90-119 días de atraso 
4: 120-149 días de atraso 
5: Deudas atrasadas o incobrables, canceladas por más de 150 días 
C: pagado ese mes 
X: No hay préstamo para el mes
"""

#Modificamos los valores de ACCOUNT STATUS para determinar si la cuenta es "COBRABLE" = 1 o "INCOBRABLE" = 0

#0: 1-29 días de atraso 
#1: 30-59 días de atraso 
#2: 60-89 días de atraso  
#3: 90-119 días de atraso 
#4: 120-149 días de atraso 
#5: Deudas atrasadas o incobrables,canceladas por más de 150 días
#6: pagado ese mes 
#7: No hay préstamo para el mes

df.loc[df['ACCOUNT_STATUS'] == '0', 'ACCOUNT_STATUS'] = '1'
df.loc[df['ACCOUNT_STATUS'] == '1', 'ACCOUNT_STATUS'] = '1'
df.loc[df['ACCOUNT_STATUS'] == '2', 'ACCOUNT_STATUS'] = '1'
df.loc[df['ACCOUNT_STATUS'] == '6', 'ACCOUNT_STATUS'] = '1'
df.loc[df['ACCOUNT_STATUS'] == '3', 'ACCOUNT_STATUS'] = '1'
df.loc[df['ACCOUNT_STATUS'] == '4', 'ACCOUNT_STATUS'] = '0'
df.loc[df['ACCOUNT_STATUS'] == '5', 'ACCOUNT_STATUS'] = '0'
df.loc[df['ACCOUNT_STATUS'] == '7', 'ACCOUNT_STATUS'] = '0'

df.value_counts("ACCOUNT_STATUS")

#Vemos tipos de datos de cada columna
df.dtypes

#Vemos info sobre null
df.info()

#Eliminamos NaN
df.isnull().sum()

df_limpio = df.dropna()
df_limpio

#Vemos cual es la ocupación mas popular
df_limpio.value_counts("OCCUPATION")

#Vemos cual es la forma de vida mas popular
df_limpio.value_counts("WAY_OF_LIVING")

#Vemos cual es el nivel de educación mas popular
df_limpio.value_counts("EDUCATION_LEVEL")

#Vemos cual es la categoria de ingresos mas popular
df_limpio.value_counts("INCOME_CATEGORY")

df_limpio.value_counts("ANNUAL_INCOME").sort_index()
df_limpio_1 = df_limpio.copy()
df_limpio_1

#Se generan rangos para la columna "Annual Income" para facilitar el análisis

#REFERENCIAS: 1(entre  0y 100.000), 2(entre  100Ky 200K), 3(entre  200Ky 300K), 4(entre 300Ky 400K), 5(entre  400Ky 500K), 6(entre  500Ky 600K), 7(entre  600Ky 700K)
#8(entre  700Ky 800K), 9(entre  800Ky 900K), 10(entre  900Ky 1M), 11(entre 1M y 1.5M), 12(entre 1.5M y 2M)

conditions = [
    (df_limpio["ANNUAL_INCOME"]> 0) & (df_limpio["ANNUAL_INCOME"]<= 100000),
    (df_limpio["ANNUAL_INCOME"]> 100000) & (df_limpio["ANNUAL_INCOME"]<= 200000),
    (df_limpio["ANNUAL_INCOME"]> 200000) & (df_limpio["ANNUAL_INCOME"]<= 300000),
    (df_limpio["ANNUAL_INCOME"]> 300000) & (df_limpio["ANNUAL_INCOME"]<= 400000),
    (df_limpio["ANNUAL_INCOME"]> 400000) & (df_limpio["ANNUAL_INCOME"]<= 500000),
    (df_limpio["ANNUAL_INCOME"]> 500000) & (df_limpio["ANNUAL_INCOME"]<= 600000),
    (df_limpio["ANNUAL_INCOME"]> 600000) & (df_limpio["ANNUAL_INCOME"]<= 700000), 
    (df_limpio["ANNUAL_INCOME"]> 700000) & (df_limpio["ANNUAL_INCOME"]<= 800000),
    (df_limpio["ANNUAL_INCOME"]> 800000) & (df_limpio["ANNUAL_INCOME"]<= 900000),
    (df_limpio["ANNUAL_INCOME"]> 900000) & (df_limpio["ANNUAL_INCOME"]<= 1000000),
    (df_limpio["ANNUAL_INCOME"]> 1000000) & (df_limpio["ANNUAL_INCOME"]<= 1500000),
    (df_limpio["ANNUAL_INCOME"]> 1500000) & (df_limpio["ANNUAL_INCOME"]<= 2000000)
    ]

values = ("1","2","3","4","5","6","7","8","9","10","11","12")
df_limpio["ANNUAL_INCOME"]= np.select(conditions,values)
df_limpio["ANNUAL_INCOME"].value_counts().sort_index()

#Hacemos variable int
df_limpio["ANNUAL_INCOME"]= df_limpio["ANNUAL_INCOME"].astype(int)

#Hacemos variable int
df_limpio["ACCOUNT_STATUS"]= df_limpio["ACCOUNT_STATUS"].astype(int)

#Corroboramos types
df_limpio.info()

#Transformamos las variables categóricas en numéricas
df_limpio = pd.get_dummies(df_limpio)
df_limpio

#Vemos las nuevas columnas y su información
df_limpio.info()

type(df_limpio)

#Grafico de barras de ACCOUNT STATUS
df_limpio["ACCOUNT_STATUS"].value_counts().plot.bar()

df_limpio.value_counts("ANNUAL_INCOME").sort_index()

df_limpio["ANNUAL_INCOME"].describe().round()

#Grafico de ANNUAL INCOME
df_limpio["ANNUAL_INCOME"].value_counts().sort_index().plot.line()
#Predominan los salarios entre $100K y $300K

#Expresado en gráfico de barrras
sns.countplot(df_limpio["ANNUAL_INCOME"])

#Expresado en boxplot
sns.boxplot(df_limpio["ANNUAL_INCOME"], orient="V")

df_limpio["ANNUAL_INCOME"].value_counts()

#Vemos la relación entre variables
plt.figure(figsize=(40, 30))

vg_corr = df_limpio.corr()
sns.heatmap(vg_corr, 
            xticklabels = vg_corr.columns.values,
            yticklabels = vg_corr.columns.values,
            annot = True);

#Creamos un sub-dataframe sobre educación 
academic = df_limpio["EDUCATION_LEVEL_Academic degree"].value_counts()
academic2= df_limpio["EDUCATION_LEVEL_Higher education"].value_counts()
academic3 = df_limpio["EDUCATION_LEVEL_Incomplete higher"].value_counts()
academic4 = df_limpio["EDUCATION_LEVEL_Lower secondary"].value_counts()
academic5= df_limpio["EDUCATION_LEVEL_Secondary / secondary special"].value_counts()
df_education = pd.DataFrame([academic,academic2,academic3,academic4,academic5])
df_education

df_education.dtypes

#Vemos como se comporta cada variable
df_education.plot.bar()

#Relacionamos EDUCATION con ANNUAL INCOME
sns.barplot(df_limpio["ANNUAL_INCOME"], df_limpio['EDUCATION_LEVEL_Academic degree'])

sns.barplot(df_limpio["ANNUAL_INCOME"], df_limpio['EDUCATION_LEVEL_Secondary / secondary special'])

#Relacionamos EDUCATION con ANNUAL INCOME
sns.barplot(df_limpio['ACCOUNT_STATUS'], df_limpio['EDUCATION_LEVEL_Secondary / secondary special'])

pd.crosstab(df_limpio["ACCOUNT_STATUS"], df_limpio["INCOME_CATEGORY_Working"])

pd.crosstab(df_limpio["ACCOUNT_STATUS"], df_limpio["ANNUAL_INCOME"])

plt.figure(figsize=(10,10))
plt.rcParams['figure.figsize'] = (12, 9)
sns.boxplot(df_limpio['ACCOUNT_STATUS'], df_limpio['ANNUAL_INCOME'], palette = 'viridis')
plt.show()

#MONTHS_BALANCE significa de que mes es el resumen de cuenta. 0 es el mes actual, -1 es el mes anterior, etc.
#STATUS significa si status de la cuenta y del pago.Significados:
  #0: 1-29 días de atraso 
  #1: 30-59 días de atraso 
  #2: 60-89 días de atraso  
  #3: 90-119 días de atraso 
  #4: 120-149 días de atraso 
  #5: Deudas atrasadas o incobrables,canceladas por más de 150 días
  #6: pagado ese mes 
  #7: No hay préstamo para el mes

plt.figure(figsize=(10,10))
plt.rcParams['figure.figsize'] = (12, 9)
sns.boxplot(df_limpio['CHILDREN'], df_limpio['BIRTHDAY'], palette = 'viridis')
plt.show()

sns.FacetGrid(df, hue="MARITAL_STATUS", size= 5).map(plt.scatter,"FAMILY_SIZE", "CHILDREN").add_legend();
plt.show

"""A partir de aqui se trabajará los algoritmos para ML

Nuestro algoritmo será de clasificación ya que queremos definir clusters de clientes.

**ALGORITMO DE CLASIFICACIÓN KNN**
"""

df_limpio

from sklearn.neighbors import KNeighborsClassifier

data = {"ANNUAL_INCOME":df_limpio["ANNUAL_INCOME"], 
        'GENDER_F':df_limpio["GENDER_F"],
        "ACCOUNT_STATUS":df_limpio["ACCOUNT_STATUS"]}

punto_nuevo = {"ANNUAL_INCOME":[2],
               "ACCOUNT_STATUS":[1]}

df = pd.DataFrame(data)
punto_nuevo = pd.DataFrame(punto_nuevo)
df

ax = plt.axes()

ax.scatter(df.loc[df["GENDER_F"] == 1 , "ANNUAL_INCOME"],
           df.loc[df["GENDER_F"] == 1 , "ACCOUNT_STATUS"],
           c="red",
            label="Women")
ax.scatter(df.loc[df['GENDER_F'] == 0 , 'ANNUAL_INCOME'],
           df.loc[df['GENDER_F'] == 0 , 'ACCOUNT_STATUS'],
           c="blue",
           label="Men")
ax.scatter(punto_nuevo['ANNUAL_INCOME'], 
           punto_nuevo['ACCOUNT_STATUS'],
           c="black")
plt.xlabel("ANNUAL_INCOME")
plt.ylabel("ACCOUNT_STATUS")
ax.legend()
plt.show()

#Entrenamos el algoritmo con las labels establecidas
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=4)
X = df_limpio[['ANNUAL_INCOME', 'ACCOUNT_STATUS']]
y = df_limpio[['GENDER_F']]

knn.fit(X, y)

#Realizamos la predicción
prediction = knn.predict(punto_nuevo)
print(prediction)

"""**ALGORITMOS DE CLASIFICACIÓN**

- Árbol de decisión
- RandomForest

"""

#Separamos los datos de entrada de la salida
X = df_limpio.drop(['ACCOUNT_STATUS'], axis=1)
y= df_limpio['ACCOUNT_STATUS']

#Importamos libreria y separamos train y test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Importamos el modelo de árbol de decision
from sklearn.tree import DecisionTreeClassifier
creditcard_tree = DecisionTreeClassifier(max_depth=4, random_state = 42)

#Entrenamos el modelo
creditcard_tree.fit(X_train,y_train)

y_train_pred = creditcard_tree.predict(X_train) #Prediccion en Train
y_test_pred = creditcard_tree.predict(X_test) #Prediccion en Test

#Generamos la matriz de confusión
from sklearn.metrics import confusion_matrix
matriz = confusion_matrix(y_test, y_test_pred)
print('Matriz de Confusión:')
print(matriz)

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(creditcard_tree, X_test, y_test)
plt.show()

from sklearn.metrics import accuracy_score

#Calculamos el accuracy en Train y Test
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print('El % de exactitud sobre el set de entrenamiento es:', train_accuracy)
print('El % de exactitud sobre el set de evaluación es:',test_accuracy)

from sklearn.metrics import roc_curve, auc

class_probabilities = creditcard_tree.predict_proba(X_test)
preds = class_probabilities[:, 1]

fpr, tpr, threshold = roc_curve(y_test, preds)
roc_auc = auc(fpr, tpr)

# AUC
print(f"AUC for our classifier is: {roc_auc}")

# Gráfica de la Curva ROC
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""**RANDOM FOREST**"""

model_randomf = RandomForestClassifier(random_state=11, n_estimators=200,
                               class_weight="balanced", max_features="log2")
model_randomf.fit(X_train, y_train)

y_test_pred = model_randomf.predict(X_test) #Prediccion en Test

from sklearn.metrics import accuracy_score

# Accuracy
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_test_pred )}")

from sklearn.metrics import roc_curve, auc

class_probabilities = model_randomf.predict_proba(X_test)
preds = class_probabilities[:, 1]

fpr, tpr, threshold = roc_curve(y_test, preds)
roc_auc = auc(fpr, tpr)

# AUC
print(f"AUC for our classifier is: {roc_auc}")

# Gráfica de la Curva ROC
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

#Comparamos modelos
creditcard_tree = DecisionTreeClassifier(max_depth=2, random_state = 50)
modelos = [creditcard_tree, model_randomf]

for i in modelos:
  modelos=i
  modelos.fit(X_train,y_train)
  y_pred=modelos.predict(X_test)
  print(accuracy_score(y_test,y_pred))

#Vemos que para nuestro dataset, tenemos mayor accuracy con Árbol de Decisión

